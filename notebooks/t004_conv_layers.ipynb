{
 "cells": [
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "# Tutorial 4: Flux Library: Convolutional Networks, Example Layers\n",
    "\n",
    "In this tutorial we will cover the following\n",
    " - What is a Convolutional Neural Network (See Hinton 2015)\n",
    " - Data sources for CNN Networks, using [MLDatasets](https://github.com/JuliaML/MLDatasets.jl) to load MINST\n",
    " - A look at [Convolution Layers, and their arguments](https://github.com/FluxML/Flux.jl/blob/master/src/layers/conv.jl#L35)\n",
    " - ConvLayers: adding, stride, width/height, activation, Determining what padding=”same” would be\n",
    " - Convolutional Layers as dimensional manipulation\n",
    " - [Inverse Convolutional Networks](https://github.com/FluxML/Flux.jl/blob/master/src/layers/conv.jl#L71), possibly with VAE\n",
    " - Putting it all together with [MINST Classifier](https://github.com/FluxML/model-zoo/blob/master/vision/mnist/conv.jl) and [VAE w/ Conv/Deconv](https://github.com/FluxML/model-zoo/blob/master/vision/mnist/vae.jl)\n",
    "\n",
    "# Load Flux\n",
    "We are just going Flux"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using Flux\n",
    "using MLDatasets\n",
    "using Test"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "# What is a Convolutional Neural Network (See Hinton 2015)\n",
    "A convolutional neural network is a network that uses convolutional transformations\n",
    "as part of the neural network, and are used for both classification and generative tasks.\n",
    "The recent revolution in Convolutional Neural Networks was spawned in the Hinton lab, by applying\n",
    "a CNN to outperfom alternative approaches on ImageNet.\n",
    "[Krizhevsky 2012 paper on ImageNet (from Hinton's Lab)](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "# Data Sources for Convolution Neural Networks\n",
    "We are going to use ImageNet, which is available from MLDatasets"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "test_x, test_y = MNIST.testdata()\n",
    "train_x, train_y = MNIST.traindata()\n",
    "\n",
    "train_x_size = (0,) # fix me!\n",
    "train_y_size = (0,); # fix me !\n",
    "@test size(train_x) == train_x_size\n",
    "@test size(train_y) == train_y_size"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "# Reshaping to WHCN Format\n",
    "For our MINST dataset, we will want to work with image data that fits\n",
    "in the following, standardized dimensions (W, H, C, N).\n",
    "where W is width in pixels, H is width in Pixels, C is number of channels, and N is number of samples.\n",
    "The Type of the array should be Array{Float, 4}\n",
    "This koan asks you to sample 100 images from MINST and convert then to WHCN format."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "N = 100\n",
    "x_train_whcn = train_x\n",
    "y = train_y # Fix me !\n",
    "@test size(X) == (28,28,1,100)\n",
    "@test size(y) == (100,)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "# Finding the output dimensions of a Conv Layers\n",
    "Given the convolution, find the output dimension after applying it to MINST"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "layer = Conv((1, 1), 1 => 32, relu, stride = (1, 1))\n",
    "output_dims = (0,) # Modify me!\n",
    "@test size(layer(X)) == output_dims"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "# Inspecting Conv Weights\n",
    "We can directly access the weights used by conv, using the accessor, `weight`\n",
    "For the follow example, determine what the dimensions of the Conv.weights would be!"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "conv_weights = Conv((3,4), 1 => 16).weight\n",
    "conv_weights_dim = (0,0,0,0) # modify me!\n",
    "conv_weights_dim = (3,4,1,16)\n",
    "@test size(conv_weights) == conv_weights_dim"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "# Find the Convolution that fits a shape\n",
    "We want to transform our 100 images of MINST such that\n",
    "our W/H is 27, and our number of channels is 42. What is a layer that will acccomplish this?"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "layer = Conv((1,1), 1=> 42, identity)\n",
    "@test size(layer(X)) == (27, 27, 42, size(X,4))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "note, we introduce the size(X,4) motif here instead of hardcoding the number of\n",
    "of examples. Further, the activation function we are using identity, has the property"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "@test identity.(X) == X\n",
    "@test identity.(y) == y"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "# Stride\n",
    "Stride, or how many pixels height/width are skipped per convolutional filter\n",
    "step, is one way to manipulate how the filter is subsequently applied to each\n",
    "image. Taking the following layer, modify its stride to get it to pass the\n",
    "dimension of the output."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "layer = Conv((1, 1), 1 => 32, relu, stride = (1, 1))\n",
    "@test size(layer(X)) == (14, 28, 32, size(X,4))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "# Padding\n",
    "Padding, is the number of pixels from the edge that are used for the convolutional\n",
    "filter. A greater padding will increase the total size of the output, and vice, versa.\n",
    "For our Conv object, the argument to set padding is `pad`. The default pad is (0,0)."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "# Padding Koan.\n",
    "Using our MINST dataset, what will be the output dimension if we use a pad of (0,1)"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "layer = Conv((1,1), 1 => 32, relu, stride = (1,1), pad = (0,1))\n",
    "size_layer_X = (28, 28, 1, 100) # size(X), we need size(layer(X))\n",
    "size_layer_X = (28, 30, 32, 100)\n",
    "@test  size(layer(X)) == size_layer_X"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "# Padding Koan # 2\n",
    "The Conv argument `pad`, can take a tuple with four arguments,\n",
    "the `Tuple{4}` arguments for pad are\n",
    "(width padding begin, width pad end, height pad start, height pad end)\n",
    "Alter the tuple passed to Conv such that the application to X has\n",
    "the dimensions (29,29,32, 100)"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "padding_argument = (0, 0, 0, 0) # modify this to get the desired output dimension\n",
    "layer = Conv((1, 1), 1 => 32, relu, stride = (1,1), pad = padding_argument)\n",
    "size_layer_X = (29,29,32,100)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "Note, in Tensorflow, we have somthing called, \"padding=SAME\". However,\n",
    "this is not available year for Flux. Instea"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "# ConvTranspose\n",
    "It is possible to reverse, or create an inverse convolutional transform using\n",
    "Flux's ConvTranspose. Given a convolutional transform, layer1, create a\n",
    "layer2 that reshapes layer1(X) into the shape of X"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "layer1 = Conv((2,2), 1 => 16, identity)\n",
    "layer2 = Conv((0,0), 0=>0, identity) # modify me !\n",
    "m = Chain(layer1, layer2)\n",
    "@test size(m(X)) == size(X)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "# Putting together a Convolutional Network\n",
    "Here is an example net that accepts images from MINST, and outputs a probability\n",
    "distribution over the 10 potential digits.\n",
    "Note the use of both `Conv`, `MaxPool`, and `softmax`, as well as\n",
    "the introduction of an anonymous function to reshape the data!\n",
    "[Example from model-zoo](https://github.com/FluxML/model-zoo/blob/master/vision/mnist/conv.jl)"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "m = Chain(\n",
    "    #= First convolution, operating upon a 28x28 image =#\n",
    "    Conv((3, 3), 1=>16, pad=(1,1), relu),\n",
    "    MaxPool((2,2)),\n",
    "    #= Second convolution, operating upon a 14x14 image =#\n",
    "    Conv((3, 3), 16=>32, pad=(1,1), relu),\n",
    "    MaxPool((2,2)),\n",
    "    #= Third convolution, operating upon a 7x7 image =#\n",
    "    Conv((3, 3), 32=>32, pad=(1,1), relu),\n",
    "    MaxPool((2,2)),\n",
    "    #= Reshape 3d tensor into a 2d one, at this point it should be (3, 3, 32, N) =#\n",
    "    #= which is where we get the 288 in the `Dense` layer below: =#\n",
    "    x -> reshape(x, :, size(x, 4)),\n",
    "    Dense(288, 10),\n",
    "    #= Finally, softmax to get nice probabilities =#\n",
    "    softmax,\n",
    ")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "# Apply a CNN to MINST\n",
    "Taking our chain from model zoo, above, and applying it a single Image of MINST\n",
    "what would we expect the output to be?"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "X_1 = reshape(X[:,:,:,1], (28,28,1,1))\n",
    "y_predicted =  m(X_1)\n",
    "y_predicted_shape = (0, 0) # modify me !\n",
    "@test size(y_predicted) == y_predicted_shape"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "# Conv is reversible!\n",
    "We can actually take a convultion transform, and revere it!\n",
    "This is the transformation behind auto-endcoders trained with\n",
    "variational inference.\n",
    "TODO: talk about the model here: https://github.com/adamwespiser/variational-autoencoders"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "#= end module =#"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "markdown",
   "source": [
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  },
  "kernelspec": {
   "name": "julia-1.2",
   "display_name": "Julia 1.2.0",
   "language": "julia"
  }
 },
 "nbformat": 4
}
